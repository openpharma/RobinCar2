---
title: "Design Doc for Survival Analysis with RobinCar2"
author: Daniel Sabanes Bove
bibliography: references.bib
number-sections: true
---

This design doc shall serve to align on the design of the survival analysis implementation in RobinCar2.

# User interface

The proposal for the user interface is the function call of the form:

```{r}
#| eval: false

robin_surv(
    Surv(time, event) ~ treatment * s1 + covariates,
    data = df,
    treatment = pb(s1),
    contrast = "hazardratio",
    pval = "logrank"
)
```

## Name and arguments

- The name `robin_surv()` indicates general survival analysis functionality. In particular, we do not need to assume a Cox proportional hazards model in order to interpret the logrank test results. 
- We use the standard `Surv(time, event)` syntax from the `survival` package, with which users are familiar already.
    - If the user would not like to adjust for covariates, they can omit the `covariates` in the formula.
    - If the user would not like to have a stratified estimate, they can omit the `s1` in the formula and in the `treatment` argument.
- We keep in line with the other RobinCar2 functions for specifying the randomization scheme via the `treatment` argument.
- For the `contrast` argument, we will start only with the hazard ratio option, as laid out in the paper by @YeShaoYi2023. 
    - In the future, this could include other contrasts, such as differences of restricted mean survival times or differences of survival probabilities at a given time point.
- The `pval` argument allows the user to specify the type of p-value they want to compute. We will start with the logrank test, but in the future we could add other options, such as p-values based on the Cox score test, which is available in the RobinCar package already.
    - This means we always both estimate the hazard ratio and perform the corresponding logrank test.

## Output

This could be the output from the `robin_surv()` function:

````
#> Model        :  Surv(time, event) ~ treatment * s1 + covariates
#> Randomization:  treatment ~ pb(s1)  ( Permuted-Block )
#> 
#> Contrast     :  Hazard ratio
#> Test         :  Logrank
#>                Estimate Std.Err Z Value  Pr(>|z|)    
#> trt1 v.s. pbo   0.56365 0.10074  5.5952 2.203e-08 ***
#> trt2 v.s. pbo   0.77093 0.10133  7.6082   0.05235 . 
#> trt2 v.s. trt1  0.20728 0.10683  1.9402 2.779e-14 *** 
#> ---
#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
````

Please note that for now there will be no "Marginal Mean" section included in the output. 
However, this could be added in the future, see @sec-questions below.

# Internal implementation

The `robincar_surv()` will follow a similar structure as e.g. `robincar_glm()`. However, the methods are quite different, e.g. here we do not have the prediction of counterfactuals. Therefore the pattern still looks quite different.

Steps include:

1. Checks
1. For each pair of treatment arms, we will compute:
   a. hazard ratio estimate (incl. standard error)
   a. p-value for the logrank test
   The details will depend on the stratification and covariate adjustment choices of the user.
1. Return the list with results, with class `surv_effect`

Note that the class of the value is not `treatment_effect` here, because we don't have marginal means, or Jacobian matrix here, in contrast to GLMs. Since there is some overlap, which could e.g. be used for the `print()` method or others, it could be helpful to have a common class `treatment_effect` and then have subclasses `glm_effect` and `surv_effect` which contain additional information.

# Questions {#sec-questions}

1. For the future, which kind of marginal means could we display? E.g. restricted mean survival times which are also covariate and stratification adjusted would be great. 
    - This would then eventually parallel the results we obtain for GLMs
    - Does the methodology exist already? E.g. from references in @MagirrWangDengMorrisBaillie2024 ?
    - Note that this can come later of course. Was just an early idea ðŸ™‚ 
1. If we have more than two treatment arms in the data set, we would currently just compute the pairwise contrasts. 
    - Is there a more efficient way to compute the pairwise hazard ratios and tests maybe?
      Team had the discussion for the binary case before, and ended up coding the multiarm case to simplify the reporting to the study team.
    - Is this sufficient? Or do we need to / could we compute an overall (logrank) test as well?    
      For now it is sufficient. Multi arm case can come later maybe, as low priority.
1. How should ties be handled?
    - The "Breslow approximation" seems simplest, see e.g. in the `survival` package's manual:

        "The Breslow approximation in essence ignores the ties. If two subjects A and B died on day 100, say, the partial likelihood will have separate terms for the two deaths. Subject A will be at risk for the death that happened to B, and B will be at risk for the death that happened to A. In life this is not technically possible of course: whoever died first will not be at risk for the second death."
    - So we use just Breslow for now.
1. If a stratum only contains a single patient, do we count this patient in `n`?
    - Question arises because this stratum then does not contribute to the statistics (summand is 0).
    - Seems we still need to count it, at least like this we match the `survival` package's result exactly.
1. In the covariate adjusted hazard ratio estimate score function, should the regression coefficients really be fixed given the original estimate? I expected them to depend on the parameter $\vartheta$ as well, but both in the paper as well as in the supplementary material they are fixed at $\widehat{\beta}_{\text{L}}$ and $\widehat{\gamma}_{\text{SL}}$ respectively.
    - Has been clarified, basically fixing the regression coefficients is a more approximate version, which is computationally simpler. We can provide both options e.g. via some expert `control` argument.

# Prototype

Here we will now include a more package-ready prototype of the survival analysis implementation, which avoids duplicate code and implements also the above described user interface. Please see the initial design doc [here](survival_initial_code.qmd) for all the details as a starting point when reading.

## Example data

As example data, also here we are going to use the NCCTG Lung Cancer Data set, which is available in the `survival` package.
We are going to use the male patients as treatment arm $j = 0$ and the female patients as treatment arm $j = 1$.

```{r}
devtools::load_all()
library(dplyr)
library(checkmate)
dat <- survival::lung |>
    mutate(
        status = factor(ifelse(status == 1, "Alive", "Dead")),
        sex = factor(ifelse(sex == 1, "Male", "Female")),
        status_numeric = as.numeric(status == "Dead"),
        strata = factor(ph.ecog)
    )
head(dat)
```

## Extracting variables

This is currently duplicating some code from `predict_counterfactual.lm()`, and we can refactor this later to avoid duplication.

```{r}
h_prepare_vars <- function(formula, data, treatment) {
    trt_vars <- h_get_vars(treatment)
    assert_data_frame(data)
    assert_subset(c(trt_vars$treatment, trt_vars$strata), colnames(data))
    assert_subset(trt_vars$treatment, all.vars(formula[[3]]))
    assert(
        test_character(data[[trt_vars$treatment]]),
        test_factor(data[[trt_vars$treatment]])
    )

    trt_lvls <- levels(data[[trt_vars$treatment]])
    n_lvls <- length(trt_lvls)
    covariates <- setdiff(all.vars(formula[[3]]), c(trt_vars$treatment, trt_vars$strata))

    # Extract survival time and censoring indicator from the left hand side of the formula.
    lhs <- formula[[2]]
    if (inherits(lhs, "call") && lhs[[1]] == as.name("Surv") || lhs[[1]] == as.name("survival::Surv")) {
        surv_vars <- as.character(lhs)[-1]
        assert_subset(surv_vars, colnames(data))
        time_var <- surv_vars[1]
        status_var <- surv_vars[2]
    } else {
        stop("Left hand side of formula must be a Surv() object.")
    }

    # Extract model without left hand side and without treatment and strata variables.
    model <- as.formula(as.call(as.list(formula)[-2L]))
    update_string <- if (length(trt_vars$strata)) {
        paste0("~ . - ", trt_vars$treatment, "*", trt_vars$strata)
    } else {
        paste("~ . -", trt_vars$treatment)
    }
    model <- update(model, as.formula(update_string))

    list(
        time = time_var,
        status = status_var,
        treatment = trt_vars$treatment,
        strata = trt_vars$strata,
        schema = trt_vars$schema,
        covariates = covariates,
        model = model,
        n_levels = n_lvls,
        levels = trt_lvls
    )
}
```

Let's test this:

```{r}
vars_strata_covs <- h_prepare_vars(
    formula = survival::Surv(time, status_numeric) ~ sex * strata + age + ph.karno + meal.cal,
    data = dat,
    treatment = sex ~ strata
)
vars_strata_covs
```

If there are no strata:

```{r}
vars_covs <- h_prepare_vars(
    formula = Surv(time, status_numeric) ~ sex + age + ph.karno + meal.cal,
    data = dat,
    treatment = sex ~ 1
)
vars_covs
```

If there are no covariates:

```{r}
vars_strata <- h_prepare_vars(
    formula = Surv(time, status_numeric) ~ sex * strata,
    data = dat,
    treatment = sex ~ strata
)
vars_strata
```

If there are no covariates and no strata:

```{r}
vars_simple <- h_prepare_vars(
    formula = Surv(time, status_numeric) ~ sex,
    data = dat,
    treatment = sex ~ 1
)
vars_simple
```

## Computation of estimates

### No strata, no covariates

Here is the first low-level function that computes score function. This comes from the initial code design doc.

```{r}
h_lr_score_no_strata_no_cov <- function(theta, df, treatment, time, status, n = nrow(df)) {
    assert_numeric(theta, min.len = 1L, finite = TRUE)
    assert_string(treatment)
    assert_string(time)
    assert_string(status)
    assert_data_frame(df)
    assert_factor(df[[treatment]], n.levels = 2L, any.missing = FALSE)
    assert_numeric(df[[status]], any.missing = FALSE)
    assert_true(all(df[[status]] %in% c(0, 1)))
    assert_numeric(df[[time]], lower = 0, any.missing = FALSE)

    # Standardize data set format, subset to relevant variables.
    df <- data.frame(
        treatment = as.numeric(df[[treatment]]) - 1L,
        time = df[[time]],
        status = df[[status]]
    )

    # Sort by time.
    df <- df[order(df$time), ]

    # Patients with events.
    df_events <- df[df$status == 1L, ]

    # Calculate the log rank statistic U_L and the variance sigma_L2 iteratively.
    U_L <- sigma_L2 <- 0
    for (i in seq_len(nrow(df_events))) {
        # This event time.
        t_i <- df_events$time[i]

        # This treatment arm indicator.
        I_i <- df_events$treatment[i]

        # Proportions of patients at risk at time t_i, per arm.
        Y_bar_1_ti <- mean(df$treatment & df$time >= t_i)
        Y_bar_0_ti <- mean(!df$treatment & df$time >= t_i)

        # Adjusted proportion of patients at risk in the treatment arm:
        Y_bar_1_ti_coxph <- Y_bar_1_ti * exp(theta)

        # Increment U_L.
        U_L <- U_L + (I_i - Y_bar_1_ti_coxph / (Y_bar_1_ti_coxph + Y_bar_0_ti))

        # Increment sigma_L2.
        sigma_L2 <- sigma_L2 + Y_bar_1_ti_coxph * Y_bar_0_ti / (Y_bar_1_ti_coxph + Y_bar_0_ti)^2
    }

    U_L <- U_L / n
    sigma_L2 <- sigma_L2 / n
    se_theta_L <- sqrt(1 / (n * sigma_L2))
    structure(
        U_L,
        sigma_L2 = sigma_L2,
        se_theta_L = se_theta_L,
        n = n
    )
}
```

Here is more general function that takes the score function and computes the log hazard ratio estimate and standard error using it:

```{r}
h_log_hr_est_via_score <- function(score_fun, interval = c(-10, 10), ...) {
    score_solution <- uniroot(
        score_fun,
        interval = interval,
        ...
    )
    list(
        theta = score_solution$root,
        se = attr(score_solution$f.root, "se_theta_L")
    )
}
```

Here is a similarly general function that computes the corresponding test:

```{r}
h_lr_test_via_score <- function(score_fun, ...) {
    score_at_0 <- score_fun(theta = 0, ...)
    U_L <- as.numeric(score_at_0)
    sigma_L2 <- attr(score_at_0, "sigma_L2")
    n <- attr(score_at_0, "n")
    tau_L <- sqrt(n) * U_L / sqrt(sigma_L2)
    pval <- 2 * pnorm(-abs(tau_L))
    list(
        U_L = U_L,
        sigma_L2 = sigma_L2,
        tau_L = tau_L,
        pval = pval
    )
}
```

Here is the high level, general function that computes both the log hazard ratio estimate and the logrank test p-value, given the score function

```{r}
robin_surv_comparison <- function(score_fun, vars, data, exp_level, control_level, ...) {
    trt_levels <- vars$levels[c(control_level, exp_level)]
    data <- data[data[[vars$treatment]] %in% trt_levels, ]
    data[[vars$treatment]] <- droplevels(data[[vars$treatment]])
    data[[vars$treatment]] <- relevel(data[[vars$treatment]], ref = trt_levels[1L])

    args <- list(
        score_fun = score_fun,
        df = data,
        ...
    )
    test_result <- do.call(h_lr_test_via_score, args)
    hr_result <- do.call(h_log_hr_est_via_score, args)

    list(
        estimate = hr_result$theta,
        se = hr_result$se,
        test_stat = test_result$tau_L,
        p_value = test_result$pval
    )
}
```

Based on this:

```{r}
robin_surv_no_strata_no_cov <- function(vars, data, exp_level, control_level) {
    robin_surv_comparison(
        score_fun = h_lr_score_no_strata_no_cov,
        vars = vars,
        data = data,
        exp_level = exp_level,
        control_level = control_level,
        treatment = vars$treatment,
        time = vars$time,
        status = vars$status
    )
}
```

Let's try it out:

```{r}
robin_surv_no_strata_no_cov(
    vars = vars_simple,
    data = dat,
    exp_level = 2,
    control_level = 1
)
```

### With strata, no covariates

Now we look at the stratified version. First again the score function:

```{r}
h_lr_score_strat <- function(theta, df, treatment, time, status, strata) {
    assert_string(strata)
    assert_data_frame(df)
    assert_factor(df[[strata]])

    # Question: Is this in the right place here? Or should it be after the na.omit()?
    n <- nrow(df)

    df <- na.omit(df[, c(treatment, time, status, strata)])
    df[[strata]] <- droplevels(df[[strata]])
    strata_levels <- levels(df[[strata]])

    df_split <- split(df, f = df[[strata]])
    strata_results <- lapply(
        df_split,
        FUN = h_lr_score_no_strata_no_cov,
        theta = theta,
        treatment = treatment,
        time = time,
        status = status,
        n = n
    )

    U_SL <- sum(sapply(strata_results, as.numeric))
    sigma_SL2 <- sum(sapply(strata_results, attr, "sigma_L2"))
    se_theta_SL <- sqrt(1 / (n * sigma_SL2))
    structure(
        U_SL,
        sigma_L2 = sigma_SL2,
        se_theta_L = se_theta_SL,
        n = n
    )
}
```

Note that in the return attributes we use standard `sigma_L2` and `se_theta_L` names, so that we can use the same `h_log_hr_est_via_score()` and `h_lr_test_via_score()` functions as before.

Based on this we can code the high-level function that computes the estimates and p-values:

```{r}
robin_surv_strata <- function(vars, data, exp_level, control_level) {
    robin_surv_comparison(
        score_fun = h_lr_score_strat,
        vars = vars,
        data = data,
        exp_level = exp_level,
        control_level = control_level,
        treatment = vars$treatment,
        time = vars$time,
        status = vars$status,
        strata = vars$strata
    )
}
```

Let's test this:

```{r}
robin_surv_strata(
    vars = vars_strata,
    data = dat,
    exp_level = 2,
    control_level = 1
)
```

### No strata, with covariates

First we need a few helper functions.

Derived outcome values:

```{r}
h_derived_outcome_vals_from_theta <- function(theta, df, treatment, time, status, covariates, n = nrow(df)) {
    assert_number(theta)
    assert_string(treatment)
    assert_string(time)
    assert_string(status)
    assert_character(covariates)
    assert_data_frame(df)
    assert_factor(df[[treatment]], n.levels = 2L)
    assert_numeric(df[[status]])
    assert_true(all(df[[status]] %in% c(0, 1)))
    assert_numeric(df[[time]], lower = 0)

    # Standardize data set format, subset to relevant variables.
    df <- data.frame(
        index = seq_len(nrow(df)),
        treatment = as.numeric(df[[treatment]]) - 1L,
        time = df[[time]],
        status = df[[status]],
        df[covariates]
    ) |>
        na.omit()

    # Sort by time.
    df <- df[order(df$time), ]

    # Patients with events.
    df_events <- df[df$status == 1L, ]

    # Unique observed event times.
    unique_times <- df_events$time |>
        split(df_events$time) |>
        sapply(length)

    df_events_unique <- data.frame(
        time = as.numeric(names(unique_times)),
        n_pts = as.numeric(unique_times)
    )

    # Add derived outcome column.
    df$O_hat <- NA_real_

    # Calculate quantities which are the same across patients first.
    # These are in parallel to df_events_unique.

    # Hazard ratio.
    exp_theta <- exp(theta)

    # Proportions of patients at risk, per unique event time and treatment arm.
    # Corresponds to \exp(\vartheta) * \bar{Y}_1(t) and \bar{Y}_0(t).
    # So here theta enters.
    at_risk_matrix <- outer(df$time, df_events_unique$time, FUN = ">=")
    Y_bar_1 <- exp_theta * colSums(df$treatment & at_risk_matrix) / n
    Y_bar_0 <- colSums(!df$treatment & at_risk_matrix) / n
    Y_bar <- Y_bar_0 + Y_bar_1

    # Proportion of patients having an event at this time.
    # Corresponds to d\bar{N}(t). Here we need to be careful about tied event times,
    # therefore we see how many patients have an event at each unique time and divide that by n.
    dN_bar <- df_events_unique$n_pts / n

    # Loop over all patients.
    for (i in seq_len(nrow(df))) {
        # Treatment arm?
        I_i <- df$treatment[i]

        # Event in this patient?
        delta_i <- df$status[i] == 1L

        # Time for this patient.
        t_i <- df$time[i]

        # Does this patient have an event at this unique event time? Corresponds to dN_ij(t).
        dN_ij <- delta_i * (df_events_unique$time == t_i)

        # Is this patient at risk at this unique event time? Corresponds to Y_ij(t).
        # Here theta enters, too.
        Y_ij <- as.numeric(t_i >= df_events_unique$time) * ifelse(I_i, exp_theta, 1)

        # Calculate the weights, Y_bar in opposite treatment arm divided by Y_bar overall.
        weights <- (I_i * Y_bar_0 + (1 - I_i) * Y_bar_1) / Y_bar

        # Compute martingale residuals.
        martingale_residuals <- dN_ij - Y_ij * dN_bar / Y_bar

        # Sum across all unique event times.
        df$O_hat[i] <- sum(weights * martingale_residuals)
    }

    df[order(df$index), ]
}
```

Linear model input:

```{r}
h_get_lm_input <- function(df, model) {
    assert_data_frame(df)
    assert_formula(model)
    assert_subset(all.vars(model), names(df))

    # Add outcome, remove intercept:
    model <- update(model, O_hat ~ . - 1)
    df_by_trt <- split(df, f = df$treatment)
    lapply(
        df_by_trt,
        function(this_df) {
            mf <- model.frame(model, data = this_df)
            X <- model.matrix(model, data = mf)
            y <- model.response(mf)
            list(X = X, y = y)
        }
    )
}
```

Linear model coefficient estimates:

```{r}
h_get_beta_estimates <- function(lm_input) {
    assert_list(lm_input, types = "list")
    assert_names(names(lm_input), identical.to = c("0", "1"))

    # Fit the model separately for each treatment arm.
    beta_est <- list()

    for (group in names(lm_input)) {
        # Get the design matrix for this treatment arm.
        X <- lm_input[[group]]$X

        # Center it.
        X <- scale(X, center = TRUE, scale = FALSE)

        # Get the derived outcome values, the response.
        y <- lm_input[[group]]$y

        # Fit the model without intercept.
        lm_fit <- lm.fit(X, y)

        # Get the coefficients.
        beta_est[[group]] <- lm_fit$coefficients
    }

    beta_est
}
```

Now we can code the score function:

```{r}
h_lr_score_cov <- function(theta, df, treatment, time, status, model, theta_hat = NULL) {
    # Calculate derived outcomes and regress them on covariates.
    theta_use <- if (is.null(theta_hat)) theta else theta_hat
    df_with_covs_ovals <- h_derived_outcome_vals_from_theta(
        theta = theta_use,
        df,
        treatment,
        time,
        status,
        covariates = all.vars(model)
    )
    lm_input <- h_get_lm_input(df_with_covs_ovals, model)
    beta_est <- h_get_beta_estimates(lm_input)

    # Obtain unadjusted result for the patients included in the two linear models.
    included_pts <- df_with_covs_ovals$index
    df_included <- df[included_pts, ]
    n <- nrow(df_included)
    unadj_score <- h_lr_score_no_strata_no_cov(theta, df_included, treatment, time, status, n = n)

    # We assume here that the observed proportion of treatment 1 in the data set corresponds to the preplanned
    # proportion of treatment 1 in the trial.
    pi <- mean(as.numeric(df[[treatment]]) - 1)

    # Overall column wise average of design matrices.
    X_all <- rbind(lm_input[["0"]]$X, lm_input[["1"]]$X)
    X_bar <- colMeans(X_all)

    # Center the design matrices with this overall average.
    X_0 <- scale(lm_input[["0"]]$X, center = X_bar, scale = FALSE)
    X_1 <- scale(lm_input[["1"]]$X, center = X_bar, scale = FALSE)

    # Compute adjustment term for U_L.
    U_L_adj_term <- (sum(X_1 %*% beta_est[["1"]]) - sum(X_0 %*% beta_est[["0"]])) / n

    # Compute adjusted U_CL.
    U_CL <- as.numeric(unadj_score) - U_L_adj_term

    # Compute adjustment term for sigma_L2.
    cov_X <- cov(X_all)
    beta_est_sum <- beta_est[["0"]] + beta_est[["1"]]
    sigma_L2_adj_term <- pi * (1 - pi) * as.numeric(t(beta_est_sum) %*% cov_X %*% beta_est_sum)

    # Compute standard error for theta estimate.
    g_theta_CL <- attr(unadj_score, "sigma_L2")
    var_theta_CL <- (g_theta_CL - sigma_L2_adj_term) / (g_theta_CL^2) / n
    se_theta_CL <- suppressWarnings(sqrt(var_theta_CL))

    structure(
        U_CL,
        se_theta_L = se_theta_CL,
        sigma_L2 = g_theta_CL - sigma_L2_adj_term,
        n = n
    )
}
```

Based on this we can code the high-level function that computes the estimates and p-values:

```{r}
robin_surv_cov <- function(vars, data, exp_level, control_level) {
    robin_surv_comparison(
        score_fun = h_lr_score_cov,
        vars = vars,
        data = data,
        exp_level = exp_level,
        control_level = control_level,
        treatment = vars$treatment,
        time = vars$time,
        status = vars$status,
        model = vars$model
    )
}
```

Let's test this:

```{r}
robin_surv_cov(
    vars = vars_covs,
    data = dat,
    exp_level = 2,
    control_level = 1
)
```

We note that currently we don't use the approximate version with `theta_hat` in the score function. Given that the results are so similar, maybe we can just skip that?

### With strata and covariates

Now finally with strata and covariates.

First again the derived outcome values function, but now stratified:

```{r}
h_strat_derived_outcome_vals_from_theta <- function(theta, df, treatment, time, status, strata, covariates) {
    assert_string(strata)
    assert_data_frame(df)
    assert_factor(df[[strata]])

    # Question: Is this in the right place here? Or should it be after the na.omit()?
    n <- nrow(df)

    df <- na.omit(df[, c(treatment, time, status, strata, covariates)])
    df[[strata]] <- droplevels(df[[strata]])
    strata_levels <- levels(df[[strata]])

    df_split <- split(df, f = df[[strata]])

    lapply(
        df_split,
        FUN = h_derived_outcome_vals_from_theta,
        theta = theta,
        treatment = treatment,
        time = time,
        status = status,
        covariates = covariates,
        n = n
    )
}
```

Then the linear model input function, but now stratified:

```{r}
h_get_strat_lm_input <- function(df_split, model) {
    assert_list(df_split, types = "data.frame")
    lapply(df_split, h_get_lm_input, model = model)
}
```

Getting the linear model coefficient estimates, but now stratified:

```{r}
h_get_strat_beta_estimates <- function(strat_lm_input) {
    assert_list(strat_lm_input, types = "list")
    assert_list(strat_lm_input[[1]], types = "list")
    assert_names(names(strat_lm_input[[1]]), identical.to = c("0", "1"))

    # Get coefficient estimates separately for each treatment arm.
    beta_est <- list()

    for (group in c("0", "1")) {
        XtXs <- list()
        Xtys <- list()

        for (stratum in names(strat_lm_input)) {
            if (group %in% names(strat_lm_input[[stratum]])) {
                # Get the design matrix for this treatment arm.
                X <- strat_lm_input[[stratum]][[group]]$X

                # Center it.
                X <- scale(X, center = TRUE, scale = FALSE)

                # Get the derived outcome values, the response.
                y <- strat_lm_input[[stratum]][[group]]$y

                # Save the cross products.
                XtXs[[stratum]] <- crossprod(X)
                Xtys[[stratum]] <- crossprod(X, y)
            }
        }

        # Sum across strata.
        XtX <- Reduce("+", XtXs)
        Xty <- Reduce("+", Xtys)

        # Get the coefficients.
        beta_est[[group]] <- solve(XtX, Xty)
    }

    beta_est
}
```

This is now the score function:

```{r}
h_lr_score_strat_cov <- function(theta, df, treatment, time, status, strata, model, theta_hat = NULL) {
    # Use row names for df such that we can see which patients are dropped etc.
    rownames(df) <- seq_len(nrow(df))

    # Calculate derived outcomes and regress them on covariates.
    theta_use <- if (is.null(theta_hat)) theta else theta_hat
    df_split_with_covs_ovals <- h_strat_derived_outcome_vals_from_theta(
        theta = theta_use,
        df,
        treatment,
        time,
        status,
        strata,
        covariates = all.vars(model)
    )
    strat_lm_input <- h_get_strat_lm_input(df_split_with_covs_ovals, model)
    beta_est <- h_get_strat_beta_estimates(strat_lm_input)

    # Obtain unadjusted result for the patients included in the two linear models.
    included_pts <- unlist(lapply(strat_lm_input, \(l) union(names(l[["0"]]$y), names(l[["1"]]$y))))
    df_included <- df[rownames(df) %in% included_pts, ]

    strat_unadj_score <- h_lr_score_strat(theta, df_included, treatment, time, status, strata)

    # We assume here that the observed proportion of treatment 1 in the data set corresponds to the preplanned
    # proportion of treatment 1 in the trial.
    pi <- mean(as.numeric(df[[treatment]]) - 1)

    # Overall column wise average of design matrices.
    strat_X_all <- lapply(strat_lm_input, \(l) rbind(l[["0"]]$X, l[["1"]]$X))
    strat_X_bar <- lapply(strat_X_all, colMeans)

    # Center the design matrices with this overall average.
    has_X_0 <- names(which(sapply(strat_lm_input, \(l) "0" %in% names(l))))
    has_X_1 <- names(which(sapply(strat_lm_input, \(l) "1" %in% names(l))))

    X_0 <- lapply(has_X_0, \(n) scale(strat_lm_input[[n]][["0"]]$X, center = strat_X_bar[[n]], scale = FALSE))
    X_1 <- lapply(has_X_1, \(n) scale(strat_lm_input[[n]][["1"]]$X, center = strat_X_bar[[n]], scale = FALSE))

    X_0 <- do.call(rbind, X_0)
    X_1 <- do.call(rbind, X_1)

    # Compute adjustment term for U_SL.
    n <- nrow(df_included)
    U_SL_adj_term <- (sum(X_1 %*% beta_est[["1"]]) - sum(X_0 %*% beta_est[["0"]])) / n

    # Compute adjusted U_CSL.
    U_CSL <- as.numeric(strat_unadj_score) - U_SL_adj_term

    # Compute adjustment term for sigma_SL2.
    strat_n <- sapply(strat_X_all, nrow)
    strat_use <- names(which(strat_n > 1))
    strat_n <- strat_n[strat_use]
    overall_n <- sum(strat_n)
    strat_cov_X <- lapply(strat_X_all[strat_use], cov)
    weighted_cov_X <- Map(\(x, n) x * n / overall_n, strat_cov_X, strat_n)
    weighted_sum_cov_X <- Reduce("+", weighted_cov_X)

    beta_est_sum <- beta_est[["0"]] + beta_est[["1"]]
    sigma_SL2_adj_term <- pi * (1 - pi) * as.numeric(t(beta_est_sum) %*% weighted_sum_cov_X %*% beta_est_sum)

    # Compute standard error for theta estimate.
    g_theta_CSL <- attr(strat_unadj_score, "sigma_L2")
    var_theta_CSL <- (g_theta_CSL - sigma_SL2_adj_term) / (g_theta_CSL^2) / n
    se_theta_CSL <- suppressWarnings(sqrt(var_theta_CSL))

    structure(
        U_CSL,
        se_theta_L = se_theta_CSL,
        sigma_L2 = g_theta_CSL - sigma_SL2_adj_term,
        n = n
    )
}
```

Based on this we can code the high-level function that computes the estimates and p-values:

```{r}
robin_surv_strata_cov <- function(vars, data, exp_level, control_level) {
    robin_surv_comparison(
        score_fun = h_lr_score_strat_cov,
        vars = vars,
        data = data,
        exp_level = exp_level,
        control_level = control_level,
        treatment = vars$treatment,
        time = vars$time,
        status = vars$status,
        strata = vars$strata,
        model = vars$model
    )
}
```

Let's test this:

```{r}
robin_surv_strata_cov(
    vars = vars_strata_covs,
    data = dat,
    exp_level = 2,
    control_level = 1
)
```

## User interface

This is how the user can analyze the data:

```{r}
robin_surv <- function(
    formula,
    data,
    treatment,
    contrast = "hazardratio",
    pval = "logrank",
    ...) {
    attr(formula, ".Environment") <- environment()
    assert_formula(formula)
    assert_data_frame(data)
    assert_formula(treatment)
    assert_subset(all.vars(formula), names(data))
    assert_subset(all.vars(treatment), names(data))
    contrast <- match.arg(contrast)
    pval <- match.arg(pval)

    vars <- h_prepare_vars(formula, data, treatment)
    data[[vars$treatment]] <- as.factor(data[[vars$treatment]])

    has_strata <- length(vars$strata) > 0
    has_covariates <- length(vars$covariates) > 0
    calc_function <- if (has_strata && has_covariates) {
        robin_surv_strata_cov
    } else if (has_strata) {
        robin_surv_strata
    } else if (has_covariates) {
        robin_surv_cov
    } else {
        robin_surv_no_strata_no_cov
    }

    comparisons <- pairwise(vars$levels)
    n_comparisons <- length(comparisons[[1]])
    estimates <- lapply(
        seq_len(n_comparisons),
        function(i) {
            exp_level <- comparisons[[1]][i]
            control_level <- comparisons[[2]][i]
            calc_function(
                vars = vars,
                data = data,
                exp_level = exp_level,
                control_level = control_level
            )
        }
    )

    result <- list(
        model = formula,
        randomization = treatment,
        schema = vars$schema,
        contrast = contrast,
        test = pval,
        pair = comparisons,
        estimate = sapply(estimates, "[[", "estimate"),
        se = sapply(estimates, "[[", "se"),
        test_stat = sapply(estimates, "[[", "test_stat"),
        p_value = sapply(estimates, "[[", "p_value")
    )

    class(result) <- "surv_effect"
    result
}
```

We then have a print method for the `surv_effect` class:

```{r}
#' @export
print.surv_effect <- function(x, ...) {
    cat("Model        : ", deparse(as.formula(x$model)), "\n")

    cat(
        "Randomization: ",
        deparse(x$randomization),
        " (",
        randomization_schema$schema[randomization_schema$id == x$schema],
        ")\n"
    )
    contr_type <- switch(x$contrast,
        hazardratio = "Hazard ratio"
    )
    cat(sprintf("\nContrast     :  %s\n", contr_type))

    test_type <- switch(x$test,
        logrank = "Log-Rank"
    )
    cat(sprintf("Test         :  %s\n\n", test_type))

    coef_mat <- matrix(
        c(
            x$estimate,
            x$se,
            x$test_stat,
            x$p_value
        ),
        nrow = length(x$estimate)
    )
    colnames(coef_mat) <- c("Estimate", "Std.Err", "Z Value", "Pr(>|z|)")
    pair <- x$pair
    row.names(coef_mat) <- sprintf("%s v.s. %s", attr(pair, "levels")[pair[[1]]], attr(pair, "levels")[pair[[2]]])
    stats::printCoefmat(
        coef_mat
    )
}
```

Let's test this with our example data:

```{r}
robin_surv(
    formula = Surv(time, status_numeric) ~ sex * strata + age + ph.karno + meal.cal,
    data = dat,
    treatment = sex ~ strata
)
```

# References
